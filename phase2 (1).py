# -*- coding: utf-8 -*-
"""Phase2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1viIRoot_Z2xrG_WTzhR3lTb95Jl9vJ2b

Imports and Data Preprocessing
"""

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns

# Load the dataset (adjust path as necessary)
data = pd.read_csv('/content/Car Sales.xlsx - car_data.csv')

# Data Preprocessing (Label Encoding categorical features)
label_encoder = LabelEncoder()
data['Dealer_Region'] = label_encoder.fit_transform(data['Dealer_Region'])
data['Company'] = label_encoder.fit_transform(data['Company'])
data['Model'] = label_encoder.fit_transform(data['Model'])
data['Body Style'] = label_encoder.fit_transform(data['Body Style'])

# Features and target for classification (Use Case 1: Market Analysis)
X_class = data[['Annual Income', 'Dealer_Region', 'Company', 'Model']]
y_class = data['Body Style']

# Train-test split (80% training, 20% testing)
X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.2, random_state=42)

""" Model Building and Evaluation"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

# Define models to train and evaluate
models = {
    'Random Forest': RandomForestClassifier(random_state=42),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'SVM': SVC(),
    'KNN': KNeighborsClassifier(),
    'Logistic Regression': LogisticRegression(max_iter=1000)
}

# Train and evaluate each model
for name, model in models.items():
    model.fit(X_train_class, y_train_class)
    y_pred = model.predict(X_test_class)
    print(f"Model: {name}")
    print(f"Accuracy: {accuracy_score(y_test_class, y_pred)}")
    print(f"Classification Report:\n{classification_report(y_test_class, y_pred, zero_division=1)}")
    print("-" * 50)

"""Hyperparameter Tuning for Random Forest"""

from sklearn.model_selection import GridSearchCV

# Hyperparameter grid for Random Forest
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Perform GridSearchCV for Random Forest
grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, verbose=2, n_jobs=-1)
grid_search.fit(X_train_class, y_train_class)

# Best hyperparameters
print(f"Best Hyperparameters: {grid_search.best_params_}")
best_rf = grid_search.best_estimator_

# Evaluate the tuned Random Forest
y_pred_best_rf = best_rf.predict(X_test_class)
print(f"Tuned Random Forest Accuracy: {accuracy_score(y_test_class, y_pred_best_rf)}")
print(f"Tuned Random Forest Report:\n{classification_report(y_test_class, y_pred_best_rf)}")

"""Misclassification Analysis"""

# Get misclassified samples from the tuned Random Forest
misclassified = np.where(y_test_class != y_pred_best_rf)[0]

# Print misclassified examples
print(f"Total misclassified samples: {len(misclassified)}")
for i in misclassified[:10]:  # Print first 10 misclassified examples
    print(f"True: {y_test_class.iloc[i]}, Predicted: {y_pred_best_rf[i]}")

"""Confusion Matrix Visualization"""

# Generate the confusion matrix for the tuned Random Forest
cm = confusion_matrix(y_test_class, y_pred_best_rf)

# Plot the confusion matrix
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4'], yticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4'])
plt.title('Confusion Matrix (Tuned Random Forest)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""Predictions"""

# Making predictions on the test set
y_pred_final = best_rf.predict(X_test_class)

# Show a few examples of actual vs predicted
results = pd.DataFrame({'Actual': y_test_class, 'Predicted': y_pred_final})
print(results.head(13))

# Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt


accuracy_results = {
    'Random Forest': 0.903,
    'Decision Tree': 0.901,
    'SVM': 0.267,
    'KNN': 0.398,
    'Logistic Regression': 0.251,

}

# Convert the accuracy results into a DataFrame
accuracy_df = pd.DataFrame(list(accuracy_results.items()), columns=['Model', 'Accuracy'])

# Visualization for accuracy per model
plt.figure(figsize=(10, 6))
plt.bar(accuracy_df['Model'], accuracy_df['Accuracy'], color='skyblue', edgecolor='black')

# Adding titles and labels
plt.title('Accuracy of Each Model', fontsize=14)
plt.xlabel('Models', fontsize=12)
plt.ylabel('Accuracy', fontsize=12)
plt.xticks(rotation=45)
plt.ylim(0, 1)  # Accuracy ranges from 0 to 1

# Display the accuracy values on top of the bars
for i, value in enumerate(accuracy_df['Accuracy']):
    plt.text(i, value + 0.01, f"{value:.2f}", ha='center', fontsize=10)

plt.tight_layout()
plt.show()

# Horizontal bar chart for model accuracy
plt.figure(figsize=(10, 6))
plt.barh(accuracy_df['Model'], accuracy_df['Accuracy'], color='lightcoral', edgecolor='black')

# Adding titles and labels
plt.title('Accuracy of Each Model', fontsize=14)
plt.xlabel('Accuracy', fontsize=12)
plt.ylabel('Models', fontsize=12)
plt.xlim(0, 1)  # Accuracy ranges from 0 to 1

# Display the accuracy values next to the bars
for i, value in enumerate(accuracy_df['Accuracy']):
    plt.text(value + 0.01, i, f"{value:.2f}", va='center', fontsize=10)

plt.tight_layout()
plt.show()

# Line plot for model accuracy
plt.figure(figsize=(10, 6))
plt.plot(accuracy_df['Model'], accuracy_df['Accuracy'], marker='o', linestyle='-', color='green', linewidth=2)

# Adding titles and labels
plt.title('Accuracy Comparison Across Models', fontsize=14)
plt.xlabel('Models', fontsize=12)
plt.ylabel('Accuracy', fontsize=12)
plt.xticks(rotation=45)
plt.ylim(0, 1)  # Accuracy ranges from 0 to 1

# Display the accuracy values at each point
for i, value in enumerate(accuracy_df['Accuracy']):
    plt.text(i, value + 0.01, f"{value:.2f}", ha='center', fontsize=10)

plt.tight_layout()
plt.show()

# Pie chart for model accuracy
plt.figure(figsize=(8, 8))
plt.pie(accuracy_df['Accuracy'], labels=accuracy_df['Model'], autopct='%1.1f%%', startangle=140, colors=plt.cm.Paired.colors)
plt.title('Accuracy Distribution Among Models', fontsize=14)
plt.axis('equal')  # Equal aspect ratio ensures that the pie chart is circular
plt.show()